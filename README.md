### Асинхронный парсер документов PEP на Scrapy.

### Описание:
Парсер создан на базе асинхронного фреймворка Scrapy. Его задача - собрать актуальную информацию о версиях PEP со страницы https://peps.python.org/ и сохранить результаты парсинга в файлах формата CSV.

### Подготовка к запуску:
**Клонируйте репозиторий:**
```
git clone https://github.com/KzarSnake/scrapy_parser_pep.git
```
**Установите и активируйте виртуальное окружение:**
```
python -m venv venv
source venv/Scripts/activate
```
**Установите зависимости из файла requirements.txt:**
```
pip install -r requirements.txt
```

### Подготовка к запуску:
Находясь в корневой директории проекта, выполните в терминале команду:
```
scrapy crawl pep
```

Результаты работы парсера будут сохранены в папке **/results**

- pep_<дата сохранения>.csv содержит номер, название и статус PEP;

- status_summary_<дата сохранения>.csv содержит статистику по всем спарсенным статусам и общее количество спарсенных документов.

### Технологии:
- Python 3.9
- Scrapy

### Автор проекта:

[Денис Свашенко](https://github.com/KzarSnake)
